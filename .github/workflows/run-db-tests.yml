name: Run package tests for all dbs

on: [push, delete]

env:
  DBT_PROFILES_DIR: ${{ github.workspace }}/
  SNOWFLAKE_RE_DATA_TESTING_ACCOUNT: ${{ secrets.SNOWFLAKE_RE_DATA_TESTING_ACCOUNT }}
  RE_DATA_TESTING_USER: ${{ secrets.RE_DATA_TESTING_USER }}
  RE_DATA_TESTING_PASSWORD: ${{ secrets.RE_DATA_TESTING_PASSWORD }}
  REDSHIFT_RE_DATA_TESTING_HOST: ${{ secrets.REDSHIFT_RE_DATA_TESTING_HOST }}
  BIGQUERY_TESTING_PROJECT_ID: ${{ secrets.BIGQUERY_TESTING_PROJECT_ID }}
  BIGQUERY_TESTING_SERVICE_ACCOUNT_BASE64: ${{ secrets.BIGQUERY_TESTING_SERVICE_ACCOUNT_BASE64 }}
  BIGQUERY_TESTING_SERVICE_ACCOUNT_PATH: ${{ github.workspace }}/bigquery-testing-service-account.json

jobs:
  test-other-dbs:
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.repository == 're-data/dbt-re-data'
    strategy:
      fail-fast: false
      matrix:
        database: [snowflake, bigquery, redshift]
    steps:        
      - name: Check out
        uses: actions/checkout@v2

      - uses: actions/setup-python@v1
        with:
          python-version: "3.7.x"

      - name: Inject slug/short variables
        uses: rlespinasse/github-slug-action@v3.x

      - name: Set the DQ_SCHEMA environment variable
        shell: bash
        run: |
          echo "DQ_SCHEMA=dq_${GITHUB_REF_SLUG//[^[:alnum:]]/_}" >> $GITHUB_ENV

      - name: Print DQ_SCHEMA
        run: |
          echo $DQ_SCHEMA

      - name: Decode service account for BigQuery
        if: matrix.database == 'bigquery'
        run: 'echo $BIGQUERY_TESTING_SERVICE_ACCOUNT_BASE64 | base64 --decode > $BIGQUERY_TESTING_SERVICE_ACCOUNT_PATH'
        shell: bash

      - name: Install dependencies
        working-directory: ./integration_tests
        run: |
          pip install -r requirements.txt
          pip install dbt-${{ matrix.database }}==1.1.0
          dbt deps

      - name: Drop schemas
        working-directory: ./integration_tests
        run: |
          dbt run-operation drop_all_schemas --args "{ schema_name: ${{ env.DQ_SCHEMA }} }" --profile re_data_${{ matrix.database }} --vars "{ source_schema: ${{ env.DQ_SCHEMA }} }"

      - name: Create Schemas if needed
        if: matrix.database == 'redshift'
        working-directory: ./integration_tests
        run: |
          dbt run-operation create_required_schemas --args "{ schema_name: ${{ env.DQ_SCHEMA }} }" --profile re_data_${{ matrix.database }} --vars "{ source_schema: ${{ env.DQ_SCHEMA }} }"

      - name: Test DB
        working-directory: ./integration_tests/python_tests
        run: |
          pytest --db ${{ matrix.database }} --source_schema ${{ env.DQ_SCHEMA }}

  test-postgres:
    runs-on: ubuntu-latest
    if: github.event_name == 'push'
    services:
      postgres:
        image: postgres
        env:
          POSTGRES_PASSWORD: postgres
        # Set health checks to wait until postgres has started
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          # Maps tcp port 5432 on service container to the host
          - 5432:5432
    steps:        
      - name: Check out
        uses: actions/checkout@v2

      - uses: actions/setup-python@v1
        with:
          python-version: "3.7.x"

      - name: Install dependencies
        working-directory: ./integration_tests
        run: |
          pip install -r requirements.txt
          dbt deps

      - name: Test DB
        working-directory: ./integration_tests/python_tests
        run: pytest --db postgres --source_schema dq

  clean-up-schemas:
    runs-on: ubuntu-latest
    if: github.event_name == 'delete' && github.repository == 're-data/dbt-re-data'
    strategy:
      fail-fast: false
      matrix:
        database: [snowflake, bigquery, redshift]
    steps:        
      - name: Check out
        uses: actions/checkout@v2

      - uses: actions/setup-python@v1
        with:
          python-version: "3.7.x"

      - name: Inject slug/short variables
        uses: rlespinasse/github-slug-action@v3.x

      - name: Set the DQ_SCHEMA environment variable
        shell: bash
        run: |
          echo "DQ_SCHEMA=dq_${GITHUB_EVENT_REF_SLUG//[^[:alnum:]]/_}" >> $GITHUB_ENV

      - name: Print DQ_SCHEMA
        run: |
          echo $DQ_SCHEMA

      - name: Decode service account for BigQuery
        if: matrix.database == 'bigquery'
        run: 'echo $BIGQUERY_TESTING_SERVICE_ACCOUNT_BASE64 | base64 --decode > $BIGQUERY_TESTING_SERVICE_ACCOUNT_PATH'
        shell: bash

      - name: Install dependencies and drop branch schema
        working-directory: ./integration_tests
        run: |
          pip install -r requirements.txt
          pip install dbt-${{ matrix.database }}==1.1.0
          dbt deps
          dbt run-operation drop_all_schemas --args "{ schema_name: ${{ env.DQ_SCHEMA }} }" --profile re_data_${{ matrix.database }} --vars "{ source_schema: ${{ env.DQ_SCHEMA }} }"